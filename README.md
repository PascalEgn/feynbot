This demo has been built following the official LlamaIndex [Starter Tutorial (Local Models)](https://docs.llamaindex.ai/en/stable/getting_started/starter_example_local/). It also implements index persistence from [Starter Tutorial (OpenAI)](https://docs.llamaindex.ai/en/stable/getting_started/starter_example/).

Models tested:

* ~~Embedding model: [BAAI/bge-small-en-v1.5](https://huggingface.co/BAAI/bge-small-en-v1.5)~~
* ~~LLM: [Llama2](https://ollama.com/library/llama2) served through [Ollama](https://github.com/ollama/ollama)~~
* [GPT-3.5-turbo](https://platform.openai.com/docs/models/gpt-3-5-turbo)

## Update (23/04/2024)

1. Local embedding model and LLM have been replaced by OpenAI's GPT-3.5-turbo
2. Gradio integration
